{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Basic Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#scientific calculations\n",
    "import scipy\n",
    "#Linear Algebra and Maltix Maltiplication and Array manipulations\n",
    "#Numpy is short for numeric python\n",
    "import numpy\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "# the package to read a csv file into a dataframe\n",
    "from pandas import read_csv\n",
    "#Machine Learning Algorithms\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset from a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are going to import the dataset from a git site using pandas read_csv\n",
    "iris = read_csv(\"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore the basic statistics of the dataset\n",
    "iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the top 5 rows of the dataframe\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the shape of the dataset#\n",
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the dataset we can see that there are 4 features and one target variable also known as the class\n",
    "#lets see how many classes are there\n",
    "\n",
    "#iris['variety'].value_counts()\n",
    "print(iris.groupby('variety').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the beauty of this dataset, very well balanced, as you do not have to apply any complex methodolgy \n",
    "#to avoid any bias, perfect for a starter\n",
    "\n",
    "#now lets see the data spread using a box plot graph\n",
    "#import plotting librarries\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#ensures that plots are  the output of plotting commands is displayed inline within frontends like the Jupyter notebook, \n",
    "#directly below the code cell that produced it. \n",
    "#The resulting plots will then also be stored in the notebook document\n",
    "\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "iris.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets do a scatter plot just to observe the data\n",
    "#discuss the shape\n",
    "\n",
    "pyplot.rcParams[\"figure.figsize\"]=8,8\n",
    "ax = iris[iris.variety=='Setosa'].plot.scatter(x='sepal.length', y='sepal.width', \n",
    "                                                    color='red', label='setosa')\n",
    "iris[iris.variety=='Versicolor'].plot.scatter(x='sepal.length', y='sepal.width', \n",
    "                                                color='green', label='versicolor', ax=ax)\n",
    "iris[iris.variety=='Virginica'].plot.scatter(x='sepal.length', y='sepal.width', \n",
    "                                                color='blue', label='virginica', ax=ax)\n",
    "ax.set_title(\"scatter\")\n",
    "\n",
    "ax2 = iris[iris.variety=='Setosa'].plot.scatter(x='petal.length', y='petal.width', \n",
    "                                                    color='red', label='setosa')\n",
    "iris[iris.variety=='Versicolor'].plot.scatter(x='petal.length', y='petal.width', \n",
    "                                                color='green', label='versicolor', ax=ax2)\n",
    "iris[iris.variety=='Virginica'].plot.scatter(x='petal.length', y='petal.width', \n",
    "                                                color='blue', label='virginica', ax=ax2)\n",
    "ax2.set_title(\"scatter\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the main data exploration exercise is to see the correlation between the feateurs\n",
    "# Seaborne is a popular package used for plotting in addition to the pyplot\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.pairplot(iris[['sepal.length', 'sepal.width', 'petal.length', 'petal.width','variety']],\n",
    "             hue=\"variety\", diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above correlation pair plots we can see a very strong correlation between petal length and petal width.\n",
    "Which means we can make a choice to drop one of these features to make the algorithm run faster\n",
    "Based on the complexity of the model we are working with and level of accuracy needed, \n",
    "it might not be a good idea to drop any of the features, however in a given situation where storage and speed may pose a problem\n",
    "than dropping a highly correlated feature is something you can consider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset for Training and Testing (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the model selection data split librarry\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.loc[:,iris.columns !='variety'],iris['variety'], stratify=iris['variety'], X_train, X_validation, Y_train, Y_validation = train_test_split(X, y,  random_state=66)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.shape)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Librarries for Models Algorithms and Model Accuracy checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Many of the algorithms available for classification\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "#Test Harness, K-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=100, shuffle=True)\n",
    "cv_results = cross_val_score(model, x_train, y_train,cv=kfold,  scoring='accuracy')\n",
    "print(\"%f  (%f)\" % (cv_results.mean(),cv_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy Score  \",accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "#model = LinearDiscriminantAnalysis()\n",
    "#model= DecisionTreeClassifier()\n",
    "#model= GaussianNB()\n",
    "#model=SVC(gamma='auto')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
